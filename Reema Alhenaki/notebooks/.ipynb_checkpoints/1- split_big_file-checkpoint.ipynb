{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04820158-a5e6-48b1-a08c-122b4582d9e5",
   "metadata": {},
   "source": [
    "# Splitting File\n",
    "In this notebook, we will read the HIS data fike which contain 4 different tables in one CSV file. We will split them into 4 different tables and ensure all columns names are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dab5b8f3-dd8f-4ebb-b056-365d53acf3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94151c29-9b52-44fe-b696-f82e2268b5bd",
   "metadata": {},
   "source": [
    "Read the big file and create new directory for new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47e64c90-157f-4bd7-9f69-4cef5eac1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "big_csv_path = \"C:/Users/reema.alhenaki/Desktop/llama3_Data/data/raw/sample_data_vida.csv\"\n",
    "output_folder = \"C:/Users/reema.alhenaki/Desktop/llama3_Data/data/split\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d486cc03-4715-4e9d-a841-887e2d47284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the big CSV fully\n",
    "df = pl.read_csv(big_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8242078-9948-4619-bdce-4119a2404b1e",
   "metadata": {},
   "source": [
    "In polars, the suffix '_duplicated' is added when it is spliting a file. This function helps to remove the suffix to ensure all columns names are correct and reflects the original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "431020d0-9e13-48e1-ae16-4c48b07691ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean '_duplicated' suffixes\n",
    "def clean_duplicated_columns(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove '_duplicated', '_duplicated_0', '_duplicated_1', etc. suffixes from column names.\n",
    "    \"\"\"\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        clean_col = re.sub(r'_duplicated(_\\d+)?$', '', col)\n",
    "        new_columns.append(clean_col)\n",
    "    return df.rename({old: new for old, new in zip(df.columns, new_columns)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f63d1-5eb4-41fc-8b43-da4e1e8618e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f2164f7-b9c4-4aeb-8482-f99159026ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert Excel column letters to index\n",
    "def excel_col_to_index(col):\n",
    "    col = col.upper()\n",
    "    index = 0\n",
    "    for i, c in enumerate(reversed(col)):\n",
    "        index += (ord(c) - ord('A') + 1) * (26 ** i)\n",
    "    return index - 1  # zero based index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5641697-1596-47a5-bad5-c16e2ee76af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all column names\n",
    "all_columns = df.columns\n",
    "\n",
    "# Define your ranges\n",
    "patient_start = excel_col_to_index('A')\n",
    "patient_end = excel_col_to_index('CR')\n",
    "vital_start = excel_col_to_index('CS')\n",
    "vital_end = excel_col_to_index('FA')\n",
    "appoint_start = excel_col_to_index('FB')\n",
    "appoint_end = excel_col_to_index('IW')\n",
    "doctor_start = excel_col_to_index('IX')\n",
    "doctor_end = excel_col_to_index('JP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82ad2dd2-edf5-4793-9ae3-440f5f1f878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns for each table\n",
    "patient_cols = all_columns[patient_start:patient_end+1]\n",
    "vital_cols = all_columns[vital_start:vital_end+1]\n",
    "appoint_cols = all_columns[appoint_start:appoint_end+1]\n",
    "doctor_cols = all_columns[doctor_start:doctor_end+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bddc3b6b-09ca-49d4-a686-6563728017a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean duplicated suffixes AFTER splitting\n",
    "df_patient = clean_duplicated_columns(df_patient)\n",
    "df_vital = clean_duplicated_columns(df_vital)\n",
    "df_appoint = clean_duplicated_columns(df_appoint)\n",
    "df_doctor = clean_duplicated_columns(df_doctor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4aac16f-2421-4338-80d7-d28607bc355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save each to CSV\n",
    "df_patient.write_csv(os.path.join(output_folder, \"HIS_Patient.csv\"))\n",
    "df_vital.write_csv(os.path.join(output_folder, \"HIS_PatientVitalSigns.csv\"))\n",
    "df_appoint.write_csv(os.path.join(output_folder, \"HIS_Appointment.csv\"))\n",
    "df_doctor.write_csv(os.path.join(output_folder, \"HIS_DoctorOrder.csv\"))\n",
    "\n",
    "print(\"Files saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama3_Data)",
   "language": "python",
   "name": "llama3_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
